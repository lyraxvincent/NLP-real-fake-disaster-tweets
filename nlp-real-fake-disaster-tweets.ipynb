{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv') # /kaggle/input/nlp-getting-started/train.csv\n",
    "test = pd.read_csv('test.csv') # /kaggle/input/nlp-getting-started/test.csv\n",
    "#sample_submission = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2818    .POTUS #StrategicPatience is a strategy for #G...\n",
       "5795    @jasalhad @brianboru67 @Jimskiv92 @hijinks1967...\n",
       "3375    Bend Post Office roofers cut gas line prompt e...\n",
       "352     Seeing that army of whitewalkers was the very ...\n",
       "5184                                          Obliterated\n",
       "2660    Apollo Brown - 'Detonate' f. M.O.P. http://t.c...\n",
       "4530    And you wonder why he's injured every year htt...\n",
       "4539    Top Stories - Google 4 dead dozens injured in ...\n",
       "5951                     *CUE THE JARIANA STANS SCREAMING\n",
       "7290    MY GIRL GOT A GIRLFRIEND CHEVY BLUE LIKE WHIRL...\n",
       "2453    @greateranglia I know the cow incident not yr ...\n",
       "1193    A Marshall Plan for the United States by Dambi...\n",
       "2400    Sound judgement by MPC - premature rises could...\n",
       "6301    @Stretcher @Rexyy @invalid @Towel let's have b...\n",
       "2160    As of 2010 there were 17 Beluga deaths reporte...\n",
       "5849    fresh out da shower lookss ?? (still loving th...\n",
       "6504    10 Ways To Survive and Escape Martial Law | Wo...\n",
       "284     RT: fittscott: Minecraft- NIGHT LUCKY BLOCK MO...\n",
       "3124    #pakistan#news# NANKANA SAHIB City News: Elect...\n",
       "3387    IbrahimMisau : FAAN orders evacuation of aband...\n",
       "6679    Random wind gust just came through #Gander.  P...\n",
       "1690    Worlds Collide When an American Family Takes O...\n",
       "5959    Harshness Follows Us a\\nBetter Day\\nby Sarah C...\n",
       "6846    Your brain is particularly vulnerable to traum...\n",
       "2462    Suresh Prabhu calls Harda derailment a natural...\n",
       "3416    Philadelphia EaglesÛª Jordan Matthews Is Goin...\n",
       "3429    Learn How I Gained Access To The Secrets Of Th...\n",
       "4821    @noah_anyname That's where the concentration c...\n",
       "4858    seeing as how this person is a mass murderer a...\n",
       "4381    RT NotExplained: The only known image of infam...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['keyword'].isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2533"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['location'].isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that have missing keyword\n",
    "##\n",
    "train = train.dropna(axis = 0,subset=['keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                       location  \\\n",
       "31  48  ablaze                     Birmingham   \n",
       "32  49  ablaze  Est. September 2012 - Bristol   \n",
       "33  50  ablaze                         AFRICA   \n",
       "34  52  ablaze               Philadelphia, PA   \n",
       "35  53  ablaze                     London, UK   \n",
       "\n",
       "                                                 text  target  \n",
       "31  @bbcmtd Wholesale Markets ablaze http://t.co/l...       1  \n",
       "32  We always try to bring the heavy. #metal #RT h...       0  \n",
       "33  #AFRICANBAZE: Breaking news:Nigeria flag set a...       1  \n",
       "34                 Crying out for more! Set me ablaze       0  \n",
       "35  On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text processing require:**  \n",
    "- remove punctuation  \n",
    "- remove numbers  \n",
    "- to lowercase  \n",
    "- remove stopwords  \n",
    "- lemmatize  \n",
    "- remove non-english words  \n",
    "\n",
    "**NOTE** : The order of the steps matter. The text processing function should execute steps in this outlined order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to process text as outlined above\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#words = nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "regex = re.compile('[^a-zA-Z]') # remove emojis and any non-letters\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_process(text):\n",
    "    cln = [c for c in text if c not in string.punctuation]\n",
    "    cln = ''.join(cln)\n",
    "    cln = [c for c in cln if not c.isdigit()]\n",
    "    cln = ''.join(cln)\n",
    "    cln = cln.lower()\n",
    "    cln = [word for word in cln.split() if word not in stopwords.words('english')]\n",
    "    cln = ' '.join(cln)\n",
    "    cln = [lemmatizer.lemmatize(word) for word in nltk.word_tokenize(cln)]\n",
    "    cln = ' '.join(cln)\n",
    "    cln = regex.sub(' ', cln)\n",
    "    cln = [word for word in nltk.wordpunct_tokenize(cln) if word in words or not word.isalpha()]\n",
    "    return cln #[word for word in cln.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=<function text_process at 0x7f7a724dc710>,\n",
       "                binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_transformer = CountVectorizer(analyzer=text_process)\n",
    "bow_transformer.fit(train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6693"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_transformer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 327)\t1\n",
      "  (0, 1049)\t1\n",
      "  (0, 2100)\t1\n",
      "  (0, 2249)\t1\n",
      "  (0, 2699)\t1\n",
      "  (0, 3019)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bow_transformer.transform([train['text'][1230]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'civilization'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer.get_feature_names()[1048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_text = bow_transformer.transform(train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7552, 6693)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_transformer.fit(bow_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3019)\t0.4700546547381698\n",
      "  (0, 2699)\t0.34618951012493654\n",
      "  (0, 2249)\t0.22878569166423807\n",
      "  (0, 2100)\t0.43926482529741256\n",
      "  (0, 1049)\t0.4700546547381698\n",
      "  (0, 327)\t0.43926482529741256\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_transformer.transform(bow_transformer.transform([train['text'][1230]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.543405753193557"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer.idf_[bow_transformer.vocabulary_['cladding']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_text = tfidf_transformer.transform(bow_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7552, 6693)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ML Algorithm Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4323\n",
       "1    3229\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, a classification algorithm eg. Logistic regression, naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_text, train['target'], test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyrax/.local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/lyrax/.local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "nb_pred = nb.predict(X_test)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Logistic Regression\n",
      "---------------------------------\n",
      "[[1162  165]\n",
      " [ 299  640]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.83      1327\n",
      "           1       0.80      0.68      0.73       939\n",
      "\n",
      "    accuracy                           0.80      2266\n",
      "   macro avg       0.80      0.78      0.78      2266\n",
      "weighted avg       0.80      0.80      0.79      2266\n",
      "\n",
      "---------------------------------\n",
      "Naive Bayes MultinomialNB\n",
      "---------------------------------\n",
      "[[1136  191]\n",
      " [ 299  640]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82      1327\n",
      "           1       0.77      0.68      0.72       939\n",
      "\n",
      "    accuracy                           0.78      2266\n",
      "   macro avg       0.78      0.77      0.77      2266\n",
      "weighted avg       0.78      0.78      0.78      2266\n",
      "\n",
      "---------------------------------\n",
      "RandomForestClassifier\n",
      "---------------------------------\n",
      "[[1089  238]\n",
      " [ 311  628]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1327\n",
      "           1       0.73      0.67      0.70       939\n",
      "\n",
      "    accuracy                           0.76      2266\n",
      "   macro avg       0.75      0.74      0.75      2266\n",
      "weighted avg       0.76      0.76      0.76      2266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------\")\n",
    "print(\"Logistic Regression\")\n",
    "print(\"---------------------------------\")\n",
    "print(confusion_matrix(y_test, lr_pred))\n",
    "print(classification_report(y_test, lr_pred))\n",
    "print(\"---------------------------------\")\n",
    "print(\"Naive Bayes MultinomialNB\")\n",
    "print(\"---------------------------------\")\n",
    "print(confusion_matrix(y_test, nb_pred))\n",
    "print(classification_report(y_test, nb_pred))\n",
    "print(\"---------------------------------\")\n",
    "print(\"RandomForestClassifier\")\n",
    "print(\"---------------------------------\")\n",
    "print(confusion_matrix(y_test, rfc_pred))\n",
    "print(classification_report(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression did quite well than the other two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break()\n",
    "#stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 29.1min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 39.5min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed: 42.7min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed: 46.6min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 52.5min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed: 54.5min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed: 57.9min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 62.8min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed: 68.2min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed: 71.2min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed: 75.0min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed: 80.3min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed: 86.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 89.8min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed: 95.4min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed: 101.6min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed: 105.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 110.6min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed: 118.1min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed: 122.3min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed: 128.5min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed: 135.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed: 140.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed: 146.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed: 152.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.7633371169125993\n",
      "Best parameters:  {'gamma': 0, 'learning_rate': 0.07, 'max_depth': 12, 'n_estimators': 500, 'objective': 'binary:logistic', 'silent': False, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Adding XgbClassifier\n",
    "##\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb = xgb.XGBClassifier()\n",
    "\n",
    "param_xgb = dict(\n",
    "    silent=[False, True],\n",
    "    learning_rate=[0.01, 0.005, 0.07],\n",
    "    subsample = [0.5, 0.7],\n",
    "    objective=['binary:logistic'], \n",
    "    n_estimators=[500, 1000], \n",
    "    max_depth=[6, 10, 12], \n",
    "    gamma=[0, 10, 30]\n",
    ")\n",
    "\n",
    "grid_xgb = GridSearchCV(estimator=xgb, param_grid=param_xgb, cv=5, n_jobs=-1, verbose=10)\n",
    "\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "print(\"Best score: \", grid_xgb.best_score_)\n",
    "print(\"Best parameters: \", grid_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters for xgbc: 'gamma': 0, 'learning_rate': 0.07, 'max_depth': 12, 'n_estimators': 500,\n",
    "# 'objective': 'binary:logistic', 'silent': False, 'subsample': 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1114  213]\n",
      " [ 303  636]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      1327\n",
      "           1       0.75      0.68      0.71       939\n",
      "\n",
      "    accuracy                           0.77      2266\n",
      "   macro avg       0.77      0.76      0.76      2266\n",
      "weighted avg       0.77      0.77      0.77      2266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "##\n",
    "pred_xgb = grid_xgb.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(confusion_matrix(y_test, pred_xgb))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test, pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a data pipeline to predict on the test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"bow cv\", CountVectorizer(analyzer=text_process)),\n",
    "    (\"tfidf\", TfidfTransformer()),\n",
    "    (\"xgbc\", XGBClassifier(gamma=0, learning_rate=0.07, max_depth=12, n_estimators=500,\n",
    "                               objective='binary:logistic', silent=False, subsample=0.7)) # (\"lr classifier\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, label_train, label_test = train_test_split(train['text'], train['target'],\n",
    "                                                                  test_size=0.3, random_state=101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow cv',\n",
       "                 CountVectorizer(analyzer=<function text_process at 0x7f7a724dc710>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\...\n",
       "                               interaction_constraints=None, learning_rate=0.07,\n",
       "                               max_delta_step=0, max_depth=12,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=500,\n",
       "                               n_jobs=0, num_parallel_tree=1,\n",
       "                               objective='binary:logistic', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               silent=False, subsample=0.7, tree_method=None,\n",
       "                               validate_parameters=False, verbosity=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(text_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_pred = pipe.predict(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 4)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2 = pd.DataFrame({\n",
    "    \"id\": test['id'],\n",
    "    \"target\": pipe_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission2.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
